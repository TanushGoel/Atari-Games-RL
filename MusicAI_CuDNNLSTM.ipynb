{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MusicAI CuDNNLSTM",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPZYXYd3ArJEADMN57Itjq3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TanushGoel/Atari-Games-RL/blob/master/MusicAI_CuDNNLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CtFYNK3c_kK",
        "colab_type": "code",
        "outputId": "119e3dfc-b8ce-4197-c9dc-49de01064b90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!pip3 -q install tensorflow-gpu==1.15.0   # ignore error messages - make sure NOT to use tensorflow 2.0, any tensorflow version between 1.13 and 1.15 will work fine"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 411.5MB 37kB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8MB 37.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 512kB 40.2MB/s \n",
            "\u001b[?25h  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: tensorflow 2.2.0 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.2.0 has requirement tensorboard<2.3.0,>=2.2.0, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.2.0 has requirement tensorflow-estimator<2.3.0,>=2.2.0, but you'll have tensorflow-estimator 1.15.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ5v5-LrdAYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 -q install keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwFLT7IBzoux",
        "colab_type": "code",
        "outputId": "b774f0ef-7e57-449d-8f9d-ce5dea4a07c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# imports\n",
        "import music21\n",
        "from music21 import converter, instrument, note, chord, stream, common\n",
        "import os\n",
        "from os import path\n",
        "import zipfile\n",
        "import glob\n",
        "import pickle\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, CuDNNLSTM\n",
        "from keras import initializers\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfrhpaHVdH7X",
        "colab_type": "code",
        "outputId": "99273b5f-32ff-4bb5-ed38-ce89c4160499",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9k66357irB2Z",
        "colab_type": "code",
        "outputId": "3437a57f-8540-44fb-8d94-819d98b41d6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-pVykyidIMq",
        "colab_type": "code",
        "outputId": "f815ecf6-0107-436d-8ba2-6d31ddf369e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.keras.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.4-tf'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JaYrzaqkPs7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# upload zip file first\n",
        "for i in os.listdir():\n",
        "  global zip_file, folder\n",
        "  if zipfile.is_zipfile(i):\n",
        "      zip_file = str(i)\n",
        "      folder = zip_file[:-4]\n",
        "      with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "          zip_ref.extractall(os.mkdir(folder))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mddrGwMu10Em",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one file at a time\n",
        "notes = []\n",
        "count = 0\n",
        "total = len(os.listdir(folder))\n",
        "\n",
        "for file in glob.glob(folder+\"/*.mid\"):\n",
        "\n",
        "    count+=1\n",
        "    print(f\"{count*100/total:1.2f}% Complete\")\n",
        "\n",
        "    try:  \n",
        "      midi = converter.parse(file)\n",
        "      parts = instrument.partitionByInstrument(midi)\n",
        "\n",
        "      if parts: # file has instrument parts\n",
        "          if len(parts.parts) > 1: # the file has more than one instrument\n",
        "            print(file, \"has more than one instrument\")\n",
        "            continue\n",
        "          else:\n",
        "            notes_to_parse = parts.parts[0].recurse()\n",
        "      else: # file has notes in a flat structure\n",
        "          notes_to_parse = midi.flat.notes\n",
        "      for element in notes_to_parse:\n",
        "          if isinstance(element, note.Note):\n",
        "              notes.append(str(element.pitch))\n",
        "          elif isinstance(element, chord.Chord):\n",
        "              notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "  \n",
        "    except:\n",
        "      print(file, \"could not be parsed\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Nh5WPiYzpHg",
        "colab_type": "code",
        "outputId": "4358d2cf-29ff-4f6b-a457-57bd1de00fcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# first check if gpu use is functional to parse multiple files in parallel\n",
        "music21.common.parallel.cpus()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrM3osbMvCAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# multiple files in parallel\n",
        "filez = []\n",
        "for file in glob.glob(folder+\"/*.mid\"):\n",
        "    filez.append(file)\n",
        "\n",
        "def get_notes(file):\n",
        "\n",
        "  notes = []\n",
        "  notes_to_parse = None\n",
        "  midi = converter.parse(file)\n",
        "  parts = instrument.partitionByInstrument(midi)\n",
        "\n",
        "  try:\n",
        "    if parts: # file has instrument parts\n",
        "        if len(parts.parts) > 1: # the file has more than one instrument\n",
        "          print(file, \"has more than one instrument\") \n",
        "        else:\n",
        "          notes_to_parse = parts.parts[0].recurse()\n",
        "    else: # file has notes in a flat structure\n",
        "        notes_to_parse = midi.flat.notes\n",
        "    for element in notes_to_parse:\n",
        "        if isinstance(element, note.Note):\n",
        "            notes.append(str(element.pitch))\n",
        "        elif isinstance(element, chord.Chord):\n",
        "            notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "  except:\n",
        "    print(file, \"could not be parsed\")\n",
        "\n",
        "  return notes\n",
        "\n",
        "output = common.runParallel(filez, parallelFunction=get_notes)\n",
        "\n",
        "notes = [j for i in range(0, len(output)) for j in output[i]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVPIBftK6dL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequence_length = 100\n",
        "\n",
        "# get all pitch names\n",
        "pitchnames = sorted(set(item for item in notes))\n",
        "\n",
        "# create a dictionary to map pitches to integers\n",
        "note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "network_input = []\n",
        "network_output = []\n",
        "\n",
        "# create input sequences and the corresponding outputs\n",
        "for i in range(0, len(notes) - sequence_length, 1):\n",
        "    sequence_in = notes[i:i + sequence_length]\n",
        "    sequence_out = notes[i + sequence_length]\n",
        "    network_input.append([note_to_int[char] for char in sequence_in])\n",
        "    network_output.append(note_to_int[sequence_out])\n",
        "    \n",
        "n_patterns = len(network_input)\n",
        "\n",
        "# reshape the input into a format compatible with CuDNNLSTM layers\n",
        "network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "\n",
        "n_vocab = np.amax(network_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uur64Fup8Tr1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normalize input\n",
        "network_input = np.divide(network_input, float(n_vocab))\n",
        "network_output = np_utils.to_categorical(network_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujz8O2deqoUC",
        "colab_type": "code",
        "outputId": "fbf44896-e0f5-46e2-aca0-39df74a15f2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "# CuDDNLSTM model\n",
        "model = Sequential()\n",
        "model.add(CuDNNLSTM(256, input_shape=(network_input.shape[1], network_input.shape[2]), return_sequences=True, kernel_initializer=initializers.RandomNormal(stddev=0.175),\n",
        "    bias_initializer=initializers.Zeros()))\n",
        "model.add(Dropout(0.225))\n",
        "model.add(CuDNNLSTM(512, return_sequences=True, kernel_initializer=initializers.RandomNormal(stddev=0.175)))\n",
        "model.add(Dropout(0.225))\n",
        "model.add(CuDNNLSTM(256, kernel_initializer=initializers.RandomNormal(stddev=0.175),\n",
        "    bias_initializer=initializers.Zeros()))\n",
        "model.add(Dense(256, kernel_initializer=initializers.RandomNormal(stddev=0.175),\n",
        "    bias_initializer=initializers.Zeros()))\n",
        "model.add(Dropout(0.225))\n",
        "model.add(Dense(n_vocab+1, kernel_initializer=initializers.RandomNormal(stddev=0.25),\n",
        "    bias_initializer=initializers.Zeros()))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_1 (CuDNNLSTM)     (None, 125, 256)          265216    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 125, 256)          0         \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_2 (CuDNNLSTM)     (None, 125, 512)          1576960   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 125, 512)          0         \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_3 (CuDNNLSTM)     (None, 256)               788480    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 174)               44718     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 174)               0         \n",
            "=================================================================\n",
            "Total params: 2,741,166\n",
            "Trainable params: 2,741,166\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4liZVKDFxAN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NYh2AdE_H0a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# checkpointer\n",
        "checkpoint = ModelCheckpoint(\"MusicAI_best.hdf5\", \n",
        "                             monitor='loss', \n",
        "                             verbose=1,        \n",
        "                             save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt84eRBeSSuI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train model\n",
        "model.fit(network_input, network_output, epochs=50, batch_size=25, callbacks=[checkpoint])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bisZ1kjn_1TH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make piece\n",
        "start = np.random.randint(0, len(network_input)-1)\n",
        "int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
        "pattern = network_input[start]\n",
        "prediction_output = []\n",
        "\n",
        "# generate 10000 notes\n",
        "for note_index in range(10000):\n",
        "    prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
        "    prediction_input = prediction_input / float(n_vocab)\n",
        "    prediction = model.predict(prediction_input, verbose=0)\n",
        "    index = np.argmax(prediction)\n",
        "    result = int_to_note[index]\n",
        "    prediction_output.append(result)\n",
        "    pattern = np.append(pattern, index)\n",
        "    pattern = pattern[1:len(pattern)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z20Ms2ruA58T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make piece\n",
        "offset = 0\n",
        "output_notes = []\n",
        "# create note and chord objects based on the values generated by the model\n",
        "for pattern in prediction_output:\n",
        "    # pattern is a chord\n",
        "    if ('.' in pattern) or pattern.isdigit():\n",
        "        notes_in_chord = pattern.split('.')\n",
        "        notes = []\n",
        "        for current_note in notes_in_chord:\n",
        "            new_note = note.Note(int(current_note))\n",
        "            new_note.storedInstrument = instrument.Piano()\n",
        "            notes.append(new_note)\n",
        "        new_chord = chord.Chord(notes)\n",
        "        new_chord.offset = offset\n",
        "        output_notes.append(new_chord)\n",
        "    # pattern is a note\n",
        "    else:\n",
        "        new_note = note.Note(pattern)\n",
        "        new_note.offset = offset\n",
        "        new_note.storedInstrument = instrument.Piano()\n",
        "        output_notes.append(new_note)\n",
        "    # increase offset each iteration so that notes do not stack\n",
        "    offset += 0.5 # offset += 0.25"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LXfXEZUBB40",
        "colab_type": "code",
        "outputId": "90812fc3-be00-4720-af12-b7ccb0205516",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# stream piece into midi file\n",
        "midi_stream = stream.Stream(output_notes)\n",
        "midi_stream.write('midi', fp='output.mid')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'output.mid'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XG8TvT9QFbLZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# download piece\n",
        "files.download('/content/output.mid')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE0YzK8CI615",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}